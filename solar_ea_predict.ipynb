{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2a3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00983778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained models and scalers\n",
    "# try:\n",
    "#     model_si = joblib.load('model_si.pkl')\n",
    "#     model_tandem_top = joblib.load('model_tandem_top.pkl')\n",
    "#     model_tandem_bot = joblib.load('model_tandem_bot.pkl')\n",
    "#     scaler_si = joblib.load('scaler_si.pkl')\n",
    "#     scaler_tandem = joblib.load('scaler_tandem.pkl')\n",
    "#     print(\"âœ… Models loaded successfully!\")\n",
    "# except:\n",
    "#     print(\"âŒ Could not load models. Please ensure model files exist.\")\n",
    "#     # Create dummy models for demonstration\n",
    "#     model_si = RandomForestRegressor()\n",
    "#     model_tandem_top = RandomForestRegressor()\n",
    "#     model_tandem_bot = RandomForestRegressor()\n",
    "#     scaler_si = StandardScaler()\n",
    "#     scaler_tandem = StandardScaler()\n",
    "\n",
    "model_si = joblib.load('model_si.pkl')\n",
    "model_tandem_top = joblib.load('model_tandem_top.pkl')\n",
    "model_tandem_bot = joblib.load('model_tandem_bot.pkl')\n",
    "scaler_si = joblib.load('scaler_si.pkl')\n",
    "scaler_tandem = joblib.load('scaler_tandem.pkl')\n",
    "print(\"âœ… Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d938725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pointillism_image(image_path, opacity_level):\n",
    "    \"\"\"Create pointillism image with specified opacity level\"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Parameters (matching the original notebook)\n",
    "    dot_density = 4\n",
    "    dot_scale = 1.0\n",
    "    alpha_value = opacity_level\n",
    "    use_adaptive_sizing = True\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"{image_path} not found.\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Optional cropping (adjust as needed)\n",
    "    img_c = img[145:145+1080, :]\n",
    "    h_c, w_c, _ = img_c.shape\n",
    "    \n",
    "    # Resize to control dot density\n",
    "    img_r = cv2.resize(img_c, (w_c // dot_density, h_c // dot_density), interpolation=cv2.INTER_AREA)\n",
    "    h_r, w_r, _ = img_r.shape\n",
    "    \n",
    "    # Convert to grayscale for brightness\n",
    "    gray = cv2.cvtColor(img_r, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Adaptive sizing\n",
    "    if use_adaptive_sizing:\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        edges = cv2.GaussianBlur(edges, (5, 5), 0)\n",
    "        size_map = 0.3 + (edges / 255.0) * 0.7\n",
    "    else:\n",
    "        size_map = np.ones_like(gray, dtype=float)\n",
    "    \n",
    "    # Build scatter data\n",
    "    lX, lY, lS, lC = [], [], [], []\n",
    "    \n",
    "    for i in range(h_r):\n",
    "        for j in range(w_r):\n",
    "            lX.append(i)\n",
    "            lY.append(j)\n",
    "            \n",
    "            brightness = gray[i, j]\n",
    "            relative_brightness = brightness / 255.0\n",
    "            size = (1.0 - relative_brightness) * 0.8 + 0.2\n",
    "            \n",
    "            size *= size_map[i, j]\n",
    "            size *= dot_scale\n",
    "            \n",
    "            lS.append(size)\n",
    "            lC.append(img_r[i, j] / 255.0)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    lX = np.array(lX)\n",
    "    lY = np.array(lY)\n",
    "    lS = np.array(lS)\n",
    "    lC = np.array(lC)\n",
    "    \n",
    "    # Normalize sizes\n",
    "    lS = 50 + (lS / lS.max()) * 150\n",
    "    \n",
    "    # Create plot\n",
    "    fig = plt.figure(figsize=(60, 60), dpi=100, facecolor='none')\n",
    "    ax = plt.subplot(111)\n",
    "    ax.patch.set_alpha(0)\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        lY, lX,\n",
    "        s=lS,\n",
    "        c=lC,\n",
    "        alpha=alpha_value,\n",
    "        edgecolors='none',\n",
    "        marker='o',\n",
    "        rasterized=True\n",
    "    )\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "    # Convert plot to image array\n",
    "    fig.canvas.draw()\n",
    "    plot_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    plot_array = plot_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return plot_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af5c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_current_from_array(image_array, model_type=\"si\"):\n",
    "    \"\"\"Predict current density from image array\"\"\"\n",
    "    # Convert array to PIL Image and then to RGBA\n",
    "    img = Image.fromarray(image_array).convert(\"RGBA\")\n",
    "    img_array = np.array(img)\n",
    "    h, w, _ = img_array.shape\n",
    "    \n",
    "    # Reshape into (n_pixels, 4)\n",
    "    pixels = img_array.reshape(-1, 4)\n",
    "    pixel_df = pd.DataFrame(pixels, columns=['R', 'G', 'B', 'A'])\n",
    "    \n",
    "    # Predict\n",
    "    if model_type.lower() == \"si\":\n",
    "        X_scaled = scaler_si.transform(pixel_df)\n",
    "        jph_preds = model_si.predict(X_scaled)\n",
    "        return np.mean(jph_preds)\n",
    "    \n",
    "    elif model_type.lower() == \"tandem\":\n",
    "        X_scaled = scaler_tandem.transform(pixel_df)\n",
    "        jph_top = model_tandem_top.predict(X_scaled)\n",
    "        jph_bot = model_tandem_bot.predict(X_scaled)\n",
    "        jph_limiting = np.minimum(jph_top, jph_bot)\n",
    "        return np.mean(jph_limiting)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Use 'si' or 'tandem'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b673f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolutionary_algorithm_optimization(image_path, model_type=\"si\", generations=10, population_size=8):\n",
    "    \"\"\"Evolutionary Algorithm to find optimal opacity level\"\"\"\n",
    "    print(\"ðŸš€ Starting Evolutionary Algorithm for opacity optimization...\")\n",
    "    \n",
    "    # Initialize population\n",
    "    population = np.random.uniform(0.1, 0.9, population_size)\n",
    "    best_opacity = 0.5\n",
    "    best_current = 0\n",
    "    \n",
    "    # Store results for analysis\n",
    "    results = []\n",
    "    \n",
    "    for generation in range(generations):\n",
    "        print(f\"\\nGeneration {generation + 1}/{generations}\")\n",
    "        generation_results = []\n",
    "        \n",
    "        for i, opacity in enumerate(population):\n",
    "            try:\n",
    "                # Create pointillism image with current opacity\n",
    "                pointillism_img = create_pointillism_image(image_path, opacity)\n",
    "                \n",
    "                # Predict current\n",
    "                current = predict_current_from_array(pointillism_img, model_type)\n",
    "                generation_results.append((opacity, current))\n",
    "                \n",
    "                print(f\"  Individual {i+1}: opacity={opacity:.3f}, current={current:.3f} mA/cmÂ²\")\n",
    "                \n",
    "                # Update best solution\n",
    "                if current > best_current:\n",
    "                    best_current = current\n",
    "                    best_opacity = opacity\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error with opacity {opacity}: {e}\")\n",
    "                generation_results.append((opacity, 0))\n",
    "        \n",
    "        results.extend(generation_results)\n",
    "        \n",
    "        # Selection: Keep best individuals\n",
    "        generation_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_individuals = generation_results[:population_size//2]\n",
    "        \n",
    "        # Crossover and Mutation\n",
    "        new_population = [ind[0] for ind in best_individuals]  # Elitism\n",
    "        \n",
    "        while len(new_population) < population_size:\n",
    "            # Select parents from best individuals\n",
    "            parent1, parent2 = np.random.choice([ind[0] for ind in best_individuals], 2, replace=False)\n",
    "            \n",
    "            # Crossover (average)\n",
    "            child = (parent1 + parent2) / 2\n",
    "            \n",
    "            # Mutation\n",
    "            mutation = np.random.normal(0, 0.1)\n",
    "            child = np.clip(child + mutation, 0.1, 0.9)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        population = np.array(new_population)\n",
    "    \n",
    "    # Find opacity with 20% loss from max current\n",
    "    target_current = best_current * 0.8\n",
    "    optimal_opacity = best_opacity\n",
    "    min_diff = float('inf')\n",
    "    \n",
    "    for opacity, current in results:\n",
    "        diff = abs(current - target_current)\n",
    "        if diff < min_diff and current >= target_current:\n",
    "            min_diff = diff\n",
    "            optimal_opacity = opacity\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Optimization Complete!\")\n",
    "    print(f\"Best opacity: {best_opacity:.3f} (Current: {best_current:.3f} mA/cmÂ²)\")\n",
    "    print(f\"Optimal opacity with 20% loss: {optimal_opacity:.3f}\")\n",
    "    print(f\"Target current: {target_current:.3f} mA/cmÂ²\")\n",
    "    \n",
    "    return optimal_opacity, best_current, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9efcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_into_cells(image_array, n_cells):\n",
    "    \"\"\"Split image into n x n grid of solar cells\"\"\"\n",
    "    h, w, _ = image_array.shape\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    cells_per_side = int(np.sqrt(n_cells))\n",
    "    if cells_per_side ** 2 != n_cells:\n",
    "        print(f\"âš ï¸ Warning: {n_cells} is not a perfect square. Using {cells_per_side**2} cells instead.\")\n",
    "        n_cells = cells_per_side ** 2\n",
    "    \n",
    "    cell_height = h // cells_per_side\n",
    "    cell_width = w // cells_per_side\n",
    "    \n",
    "    cells = []\n",
    "    positions = []\n",
    "    \n",
    "    for i in range(cells_per_side):\n",
    "        for j in range(cells_per_side):\n",
    "            y_start = i * cell_height\n",
    "            y_end = (i + 1) * cell_height\n",
    "            x_start = j * cell_width\n",
    "            x_end = (j + 1) * cell_width\n",
    "            \n",
    "            cell = image_array[y_start:y_end, x_start:x_end]\n",
    "            cells.append(cell)\n",
    "            positions.append((i, j))\n",
    "    \n",
    "    return cells, positions, cells_per_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151fd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_solar_cells(image_path, optimal_opacity, n_cells, model_type=\"si\"):\n",
    "    \"\"\"Analyze current density for each solar cell\"\"\"\n",
    "    print(f\"\\nðŸ”¬ Analyzing {n_cells} solar cells with opacity {optimal_opacity:.3f}...\")\n",
    "    \n",
    "    # Create pointillism image with optimal opacity\n",
    "    pointillism_img = create_pointillism_image(image_path, optimal_opacity)\n",
    "    \n",
    "    # Split into cells\n",
    "    cells, positions, grid_size = split_image_into_cells(pointillism_img, n_cells)\n",
    "    \n",
    "    # Calculate current density for each cell\n",
    "    cell_currents = []\n",
    "    for i, cell in enumerate(cells):\n",
    "        current = predict_current_from_array(cell, model_type)\n",
    "        cell_currents.append(current)\n",
    "        print(f\"  Cell {i+1} (row {positions[i][0]}, col {positions[i][1]}): {current:.3f} mA/cmÂ²\")\n",
    "    \n",
    "    # Create current density matrix\n",
    "    current_matrix = np.zeros((grid_size, grid_size))\n",
    "    for (row, col), current in zip(positions, cell_currents):\n",
    "        current_matrix[row, col] = current\n",
    "    \n",
    "    return cell_currents, current_matrix, grid_size, pointillism_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d9a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_currents(cell_currents, method=\"lowest\"):\n",
    "    \"\"\"Equalize currents to match the specified method\"\"\"\n",
    "    if method == \"lowest\":\n",
    "        target_current = min(cell_currents)\n",
    "    elif method == \"average\":\n",
    "        target_current = np.mean(cell_currents)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'lowest' or 'average'\")\n",
    "    \n",
    "    equalized_currents = [target_current] * len(cell_currents)\n",
    "    \n",
    "    print(f\"\\nâš¡ Current equalization ({method} method):\")\n",
    "    print(f\"Target current: {target_current:.3f} mA/cmÂ²\")\n",
    "    print(f\"Original current range: {min(cell_currents):.3f} - {max(cell_currents):.3f} mA/cmÂ²\")\n",
    "    print(f\"Equalized all cells to: {target_current:.3f} mA/cmÂ²\")\n",
    "    \n",
    "    return equalized_currents, target_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c57769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Solar Cell Current Density Analysis ===\n",
      "Image: CJ.png\n",
      "Model: si\n",
      "Number of cells: 9\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Evolutionary Algorithm for opacity optimization...\n",
      "\n",
      "Generation 1/8\n",
      "  Individual 1: opacity=0.189, current=11.883 mA/cmÂ²\n",
      "  Individual 2: opacity=0.546, current=11.878 mA/cmÂ²\n",
      "  Individual 3: opacity=0.626, current=11.878 mA/cmÂ²\n",
      "  Individual 4: opacity=0.202, current=11.883 mA/cmÂ²\n",
      "  Individual 5: opacity=0.350, current=11.881 mA/cmÂ²\n",
      "  Individual 6: opacity=0.390, current=11.881 mA/cmÂ²\n",
      "\n",
      "Generation 2/8\n",
      "  Individual 1: opacity=0.189, current=11.883 mA/cmÂ²\n",
      "  Individual 2: opacity=0.202, current=11.883 mA/cmÂ²\n",
      "  Individual 3: opacity=0.350, current=11.881 mA/cmÂ²\n",
      "  Individual 4: opacity=0.261, current=11.881 mA/cmÂ²\n",
      "  Individual 5: opacity=0.226, current=11.883 mA/cmÂ²\n",
      "  Individual 6: opacity=0.358, current=11.881 mA/cmÂ²\n",
      "\n",
      "Generation 3/8\n",
      "  Individual 1: opacity=0.189, current=11.883 mA/cmÂ²\n",
      "  Individual 2: opacity=0.202, current=11.883 mA/cmÂ²\n",
      "  Individual 3: opacity=0.226, current=11.883 mA/cmÂ²\n",
      "  Individual 4: opacity=0.222, current=11.883 mA/cmÂ²\n",
      "  Individual 5: opacity=0.199, current=11.883 mA/cmÂ²\n",
      "  Individual 6: opacity=0.223, current=11.883 mA/cmÂ²\n",
      "\n",
      "Generation 4/8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Step 1: Find optimal opacity using Evolutionary Algorithm\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m optimal_opacity, max_current, ea_results = \u001b[43mevolutionary_algorithm_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mIMAGE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_TYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Step 2: Split image into solar cells and analyze current densities\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mevolutionary_algorithm_optimization\u001b[39m\u001b[34m(image_path, model_type, generations, population_size)\u001b[39m\n\u001b[32m     20\u001b[39m pointillism_img = create_pointillism_image(image_path, opacity)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Predict current\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m current = \u001b[43mpredict_current_from_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpointillism_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m generation_results.append((opacity, current))\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Individual \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: opacity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopacity\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, current=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m mA/cmÂ²\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mpredict_current_from_array\u001b[39m\u001b[34m(image_array, model_type)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_type.lower() == \u001b[33m\"\u001b[39m\u001b[33msi\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     14\u001b[39m     X_scaled = scaler_si.transform(pixel_df)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     jph_preds = \u001b[43mmodel_si\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(jph_preds)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_type.lower() == \u001b[33m\"\u001b[39m\u001b[33mtandem\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1078\u001b[39m, in \u001b[36mForestRegressor.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1076\u001b[39m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[32m   1077\u001b[39m lock = threading.Lock()\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msharedmem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1083\u001b[39m y_hat /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_)\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:730\u001b[39m, in \u001b[36m_accumulate_prediction\u001b[39m\u001b[34m(predict, X, out, lock)\u001b[39m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[32m    724\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    725\u001b[39m \u001b[33;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[32m    726\u001b[39m \n\u001b[32m    727\u001b[39m \u001b[33;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[33;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m     prediction = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m    732\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nalaw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:531\u001b[39m, in \u001b[36mBaseDecisionTree.predict\u001b[39m\u001b[34m(self, X, check_input)\u001b[39m\n\u001b[32m    529\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    530\u001b[39m X = \u001b[38;5;28mself\u001b[39m._validate_X_predict(X, check_input)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m proba = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m n_samples = X.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# Classification\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    IMAGE_PATH = \"CJ.png\"  # Replace with your image path\n",
    "    MODEL_TYPE = \"si\"  # \"si\" or \"tandem\"\n",
    "    N_CELLS = 9  # Number of solar cells (should be perfect square: 4, 9, 16, 25, etc.)\n",
    "    \n",
    "    print(\"=== Solar Cell Current Density Analysis ===\")\n",
    "    print(f\"Image: {IMAGE_PATH}\")\n",
    "    print(f\"Model: {MODEL_TYPE}\")\n",
    "    print(f\"Number of cells: {N_CELLS}\")\n",
    "    \n",
    "    # Step 1: Find optimal opacity using Evolutionary Algorithm\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    optimal_opacity, max_current, ea_results = evolutionary_algorithm_optimization(\n",
    "        IMAGE_PATH, MODEL_TYPE, generations=8, population_size=6\n",
    "    )\n",
    "    \n",
    "    # Step 2: Split image into solar cells and analyze current densities\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    cell_currents, current_matrix, grid_size, processed_img = analyze_solar_cells(\n",
    "        IMAGE_PATH, optimal_opacity, N_CELLS, MODEL_TYPE\n",
    "    )\n",
    "    \n",
    "    # Step 3: Equalize currents to match the lowest cell\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    equalized_currents, target_current = equalize_currents(cell_currents, method=\"lowest\")\n",
    "    \n",
    "    # Visualization\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“Š Generating visualizations...\")\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Original pointillism image\n",
    "    axes[0, 0].imshow(processed_img)\n",
    "    axes[0, 0].set_title(f'Pointillism Image (Opacity: {optimal_opacity:.3f})')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Plot 2: Current density heatmap\n",
    "    im = axes[0, 1].imshow(current_matrix, cmap='plasma', aspect='equal')\n",
    "    axes[0, 1].set_title('Current Density Heatmap (mA/cmÂ²)')\n",
    "    axes[0, 1].set_xlabel('Column')\n",
    "    axes[0, 1].set_ylabel('Row')\n",
    "    \n",
    "    # Add values to heatmap\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            axes[0, 1].text(j, i, f'{current_matrix[i, j]:.2f}', \n",
    "                           ha='center', va='center', color='white', fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=axes[0, 1])\n",
    "    \n",
    "    # Plot 3: Original vs Equalized currents\n",
    "    x_pos = np.arange(len(cell_currents))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 0].bar(x_pos - width/2, cell_currents, width, label='Original', alpha=0.7)\n",
    "    axes[1, 0].bar(x_pos + width/2, equalized_currents, width, label='Equalized', alpha=0.7)\n",
    "    axes[1, 0].axhline(y=target_current, color='r', linestyle='--', label=f'Target: {target_current:.3f} mA/cmÂ²')\n",
    "    axes[1, 0].set_xlabel('Solar Cell Index')\n",
    "    axes[1, 0].set_ylabel('Current Density (mA/cmÂ²)')\n",
    "    axes[1, 0].set_title('Original vs Equalized Currents')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].set_xticks(x_pos)\n",
    "    \n",
    "    # Plot 4: EA optimization progress\n",
    "    opacities, currents = zip(*ea_results)\n",
    "    axes[1, 1].scatter(opacities, currents, alpha=0.6, c=currents, cmap='viridis')\n",
    "    axes[1, 1].axvline(x=optimal_opacity, color='red', linestyle='--', label=f'Optimal: {optimal_opacity:.3f}')\n",
    "    axes[1, 1].set_xlabel('Opacity Level')\n",
    "    axes[1, 1].set_ylabel('Current Density (mA/cmÂ²)')\n",
    "    axes[1, 1].set_title('EA Optimization Results')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“ˆ SUMMARY STATISTICS\")\n",
    "    print(f\"Optimal opacity level: {optimal_opacity:.3f}\")\n",
    "    print(f\"Maximum current density: {max_current:.3f} mA/cmÂ²\")\n",
    "    print(f\"Target current (20% loss): {max_current * 0.8:.3f} mA/cmÂ²\")\n",
    "    print(f\"Number of solar cells: {N_CELLS}\")\n",
    "    print(f\"Grid configuration: {grid_size} Ã— {grid_size}\")\n",
    "    print(f\"Original current statistics:\")\n",
    "    print(f\"  - Mean: {np.mean(cell_currents):.3f} mA/cmÂ²\")\n",
    "    print(f\"  - Std: {np.std(cell_currents):.3f} mA/cmÂ²\")\n",
    "    print(f\"  - Min: {np.min(cell_currents):.3f} mA/cmÂ²\")\n",
    "    print(f\"  - Max: {np.max(cell_currents):.3f} mA/cmÂ²\")\n",
    "    print(f\"Equalized current: {target_current:.3f} mA/cmÂ²\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Cell_Index': range(1, len(cell_currents) + 1),\n",
    "        'Row': [pos[0] for pos in positions],\n",
    "        'Column': [pos[1] for pos in positions],\n",
    "        'Original_Current': cell_currents,\n",
    "        'Equalized_Current': equalized_currents\n",
    "    })\n",
    "    \n",
    "    results_df.to_csv('solar_cell_analysis_results.csv', index=False)\n",
    "    print(f\"\\nðŸ’¾ Results saved to 'solar_cell_analysis_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
